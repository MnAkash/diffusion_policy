_target_: diffusion_policy.workspace.train_diffusion_unet_hybrid_workspace.TrainDiffusionUnetHybridWorkspace
name: train_diffusion_unet_hybrid

# ---------- checkpoints ----------
checkpoint:
  save_last_ckpt: true
  save_last_snapshot: false
  topk:
    format_str: "epoch={epoch:04d}-val_loss={val_loss:.6f}.ckpt"
    k: 5
    mode: min
    monitor_key: val_loss
    
    
# ---------- dataloaders ----------
dataloader:
  batch_size: 64          # 240x320 is big; increase if VRAM allows
  num_workers: 12
  persistent_workers: true
  pin_memory: true
  shuffle: true

dataset_obs_steps: 2

# ---------- EMA ----------
ema:
  _target_: diffusion_policy.model.diffusion.ema_model.EMAModel
  inv_gamma: 1.0
  max_value: 0.9999
  min_value: 0.0
  power: 0.75
  update_after_step: 0

# ---------- core DP horizon/steps ----------
horizon: 16              # 1.6s @ 10Hz

# ---------- logging ----------
logging:
  group: null
  id: null
  mode: offline
  name: sweep_clean_unet_hybrid
  project: diffusion_policy
  resume: true
  tags:
  - train_diffusion_unet_hybrid
  - sweep_clean
  - default

n_action_steps: 8        # Ta
n_latency_steps: 0
n_obs_steps: 2           # To
past_action_visible: false
obs_as_global_cond: true

# ---------- optimizer ----------
optimizer:
  _target_: torch.optim.AdamW
  lr: 1.0e-4
  betas: [0.95, 0.999]
  eps: 1.0e-8
  weight_decay: 1.0e-6

# ---------- policy ----------
policy:
  _target_: diffusion_policy.policy.diffusion_unet_hybrid_image_policy.DiffusionUnetHybridImagePolicy
  horizon: ${horizon}
  n_obs_steps: ${n_obs_steps}
  n_action_steps: ${n_action_steps}

  # With 240x320, cropping helps GPU + regularization.
  # If you want NO crop, set crop_shape: [240, 320]
  crop_shape: [224, 224]
  eval_fixed_crop: true

  obs_as_global_cond: ${obs_as_global_cond}
  obs_encoder_group_norm: true
  cond_predict_scale: true

  diffusion_step_embed_dim: 128
  kernel_size: 5
  n_groups: 8
  down_dims: [512, 1024, 2048]

  noise_scheduler:
    _target_: diffusers.schedulers.scheduling_ddpm.DDPMScheduler
    num_train_timesteps: 100
    beta_start: 0.0001
    beta_end: 0.02
    beta_schedule: squaredcos_cap_v2
    clip_sample: true
    prediction_type: epsilon
    variance_type: fixed_small

  num_inference_steps: 100

  shape_meta: &shape_meta
    action:
      shape: [10]
    obs:
      images_0: # isometric camera
        shape: [3, 240, 320]
        type: rgb
      images_2: # hand camera
        shape: [3, 240, 320]
        type: rgb
      joint_states:
        shape: [7]
        type: low_dim
      ee_states:
        shape: [10]
        type: low_dim

# ---------- task ----------
task:
  name: sweep_clean
  image_shape: [3, 240, 320]
  shape_meta: *shape_meta

  # Your custom dataset that reads your zarr converted from H5.
  # You will set this to whatever class you create in the repo.
  dataset:
    _target_: diffusion_policy.dataset.spot_zarr_image_dataset.SpotZarrImageDataset
    zarr_path: data/spot/sweep_clean_replay.zarr

    horizon: ${horizon}
    n_obs_steps: ${dataset_obs_steps}
    n_action_steps: ${n_action_steps}
    pad_before: ${eval:'${n_obs_steps}-1'}
    pad_after: ${eval:'${n_action_steps}-1'}
    seed: 42
    val_ratio: 0.10          # ~10 demos held out if you have ~100 demos
    max_train_episodes: 100

    # These tell your dataset class which arrays to read from zarr
    rgb_keys: [images_0, images_2]
    lowdim_keys: [joint_states, ee_states]
    use_cache: true

  # If you donâ€™t have an environment runner, disable rollouts by setting a huge rollout_every.
  # Many users do this when training purely offline.
  env_runner:
    _target_: diffusion_policy.env_runner.null_image_runner.NullImageRunner

task_name: sweep_clean

# ---------- training loop ----------
training:
  checkpoint_every: 50
  debug: false
  device: cuda:0
  gradient_accumulate_every: 1
  lr_scheduler: cosine
  lr_warmup_steps: 500
  max_train_steps: null
  max_val_steps: null
  num_epochs: 500
  resume: true
  # offline-only: avoid env rollouts
  rollout_every: 999999
  sample_every: 5
  seed: 42
  tqdm_interval_sec: 1.0
  use_ema: true
  val_every: 1

val_dataloader:
  batch_size: 64
  num_workers: 12
  persistent_workers: true
  pin_memory: true
  shuffle: false
